{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9ae711",
   "metadata": {},
   "source": [
    "\n",
    "# üìä Data Analysis for Student Performance Prediction\n",
    "\n",
    "## üîç Overview\n",
    "This Jupyter Notebook performs an **exploratory data analysis (EDA)** on the *Students Performance Dataset*. \n",
    "It is designed to provide insights into student performance based on various factors, such as study habits, parental involvement, and demographic attributes.\n",
    "\n",
    "This analysis will help in building models for:\n",
    "1. **User Story 1: Supervised Learning Model** ‚Äì Predicting a student‚Äôs likelihood of passing based on study habits and past scores.\n",
    "2. **User Story 2: Clustering Model** ‚Äì Grouping students based on learning styles for personalized teaching strategies.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de6cc3",
   "metadata": {},
   "source": [
    "\n",
    "## üì¶ Step 1: Importing Required Libraries\n",
    "We begin by importing essential Python libraries:\n",
    "- **pandas** and **numpy** for data manipulation.\n",
    "- **matplotlib** and **seaborn** for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5766b4f",
   "metadata": {},
   "source": [
    "\n",
    "## üìÇ Step 2: Loading the Dataset\n",
    "The dataset is read into a pandas DataFrame for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "file_path = \"Student_performance_data _.csv\"  # Ensure this file is in the same directory\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257db787",
   "metadata": {},
   "source": [
    "\n",
    "## üìù Step 3: Understanding the Data\n",
    "Let's explore the dataset structure, including:\n",
    "- Column names and data types.\n",
    "- Presence of missing values.\n",
    "- Basic statistical summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic information about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "display(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a2650",
   "metadata": {},
   "source": [
    "\n",
    "## üé≠ Step 4: Exploring Categorical Features\n",
    "Examining the unique values in categorical columns to understand their distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b774ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check unique values in categorical columns\n",
    "print(\"\\nUnique values in categorical columns:\")\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591895f",
   "metadata": {},
   "source": [
    "\n",
    "## üìä Step 5: Visualizing Numerical Features\n",
    "Understanding the distribution of numerical variables helps in feature selection and preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6348def",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the distribution of numerical features\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[numerical_cols].hist(figsize=(12, 8), bins=20, edgecolor='black')\n",
    "plt.suptitle(\"Distribution of Numerical Features\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adae40cf",
   "metadata": {},
   "source": [
    "\n",
    "## üîó Step 6: Correlation Analysis\n",
    "A heatmap of the correlation matrix helps identify relationships between numerical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check correlation matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db34fe3e",
   "metadata": {},
   "source": [
    "\n",
    "## üìä Step 7: Visualizing Categorical Features\n",
    "We analyze categorical variables using **count plots** to understand student distribution across different categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af02b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Countplot for categorical variables\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(y=df[col], palette=\"viridis\")\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16911ca5",
   "metadata": {},
   "source": [
    "\n",
    "## üîÑ Step 8: Encoding Categorical Variables for Model Training\n",
    "Machine learning models require numerical input. We convert categorical variables into **dummy variables** using one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encoding categorical variables for model training (if needed)\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Display encoded dataset\n",
    "print(\"\\nEncoded Dataset Sample:\")\n",
    "display(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5cc7f",
   "metadata": {},
   "source": [
    "### **üìå Next Steps**\n",
    "\n",
    "Once we analyze the dataset, the next step is:\n",
    "\n",
    "-   **Feature Selection:** Identify relevant features for prediction (study habits, past scores, tutoring, etc.).\n",
    "-   **Define Target Variable:** Convert grades into a **binary pass/fail** label for classification.\n",
    "-   **Build ML Models:** Start with **Logistic Regression** for prediction and **K-Means Clustering** for student grouping.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffbae28",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
