{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8c9ae711","cell_type":"markdown","source":"\n# üìä Data Analysis for Student Performance Prediction\n\n## üîç Overview\nThis Jupyter Notebook performs an **exploratory data analysis (EDA)** on the *Students Performance Dataset*. \nIt is designed to provide insights into student performance based on various factors, such as study habits, parental involvement, and demographic attributes.\n\nThis analysis will help in building models for:\n1. **User Story 1: Supervised Learning Model** ‚Äì Predicting a student‚Äôs likelihood of passing based on study habits and past scores.\n2. **User Story 2: Clustering Model** ‚Äì Grouping students based on learning styles for personalized teaching strategies.\n\n---\n","metadata":{}},{"id":"87de6cc3","cell_type":"markdown","source":"\n## üì¶ Step 1: Importing Required Libraries\nWe begin by importing essential Python libraries:\n- **pandas** and **numpy** for data manipulation.\n- **matplotlib** and **seaborn** for visualization.\n","metadata":{}},{"id":"6792e2f5","cell_type":"code","source":"\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T21:59:19.920725Z","iopub.execute_input":"2025-03-03T21:59:19.920992Z","iopub.status.idle":"2025-03-03T21:59:23.328138Z","shell.execute_reply.started":"2025-03-03T21:59:19.920966Z","shell.execute_reply":"2025-03-03T21:59:23.327029Z"}},"outputs":[],"execution_count":1},{"id":"e5766b4f","cell_type":"markdown","source":"\n## üìÇ Step 2: Loading the Dataset\nThe dataset is read into a pandas DataFrame for analysis.\n","metadata":{}},{"id":"c882a059","cell_type":"code","source":"\n# Load the dataset\nfile_path = \"/kaggle/input/students-performance-dataset/Student_performance_data _.csv\"  # Ensure this file is in the same directory\ndf = pd.read_csv(file_path)\n\n# Display first few rows\nprint(\"First 5 rows of the dataset:\")\ndisplay(df.head())\n","metadata":{},"outputs":[],"execution_count":null},{"id":"257db787","cell_type":"markdown","source":"\n## üìù Step 3: Understanding the Data\nLet's explore the dataset structure, including:\n- Column names and data types.\n- Presence of missing values.\n- Basic statistical summary.\n","metadata":{}},{"id":"8644c575","cell_type":"code","source":"\n# Basic information about the dataset\nprint(\"\\nDataset Info:\")\ndf.info()\n\n# Check for missing values\nprint(\"\\nMissing Values:\")\nprint(df.isnull().sum())\n\n# Summary statistics\nprint(\"\\nSummary Statistics:\")\ndisplay(df.describe())\n","metadata":{},"outputs":[],"execution_count":null},{"id":"910a2650","cell_type":"markdown","source":"\n## üé≠ Step 4: Exploring Categorical Features\nExamining the unique values in categorical columns to understand their distribution.\n","metadata":{}},{"id":"b3b774ad","cell_type":"code","source":"\n# Check unique values in categorical columns\nprint(\"\\nUnique values in categorical columns:\")\nfor col in df.select_dtypes(include=['object']).columns:\n    print(f\"{col}: {df[col].unique()}\")\n","metadata":{},"outputs":[],"execution_count":null},{"id":"6591895f","cell_type":"markdown","source":"\n## üìä Step 5: Visualizing Numerical Features\nUnderstanding the distribution of numerical variables helps in feature selection and preprocessing.\n","metadata":{}},{"id":"d6348def","cell_type":"code","source":"\n# Visualize the distribution of numerical features\nnumerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\ndf[numerical_cols].hist(figsize=(12, 8), bins=20, edgecolor='black')\nplt.suptitle(\"Distribution of Numerical Features\", fontsize=14)\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"adae40cf","cell_type":"markdown","source":"\n## üîó Step 6: Correlation Analysis\nA heatmap of the correlation matrix helps identify relationships between numerical features.\n","metadata":{}},{"id":"1079c790","cell_type":"code","source":"\n# Check correlation matrix\nplt.figure(figsize=(10, 6))\nsns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\nplt.title(\"Correlation Matrix\")\nplt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"db34fe3e","cell_type":"markdown","source":"\n## üìä Step 7: Visualizing Categorical Features\nWe analyze categorical variables using **count plots** to understand student distribution across different categories.\n","metadata":{}},{"id":"6af02b97","cell_type":"code","source":"\n# Countplot for categorical variables\ncategorical_cols = df.select_dtypes(include=['object']).columns\nfor col in categorical_cols:\n    plt.figure(figsize=(8, 4))\n    sns.countplot(y=df[col], palette=\"viridis\")\n    plt.title(f\"Distribution of {col}\")\n    plt.show()\n","metadata":{},"outputs":[],"execution_count":null},{"id":"16911ca5","cell_type":"markdown","source":"\n## üîÑ Step 8: Encoding Categorical Variables for Model Training\nMachine learning models require numerical input. We convert categorical variables into **dummy variables** using one-hot encoding.\n","metadata":{}},{"id":"f61a3acb","cell_type":"code","source":"\n# Encoding categorical variables for model training (if needed)\ndf_encoded = pd.get_dummies(df, drop_first=True)\n\n# Display encoded dataset\nprint(\"\\nEncoded Dataset Sample:\")\ndisplay(df_encoded.head())\n","metadata":{},"outputs":[],"execution_count":null},{"id":"77f5cc7f","cell_type":"markdown","source":"### **üìå Next Steps**\n\nOnce we analyze the dataset, the next step is:\n\n-   **Feature Selection:** Identify relevant features for prediction (study habits, past scores, tutoring, etc.).\n-   **Define Target Variable:** Convert grades into a **binary pass/fail** label for classification.\n-   **Build ML Models:** Start with **Logistic Regression** for prediction and **K-Means Clustering** for student grouping.\n\n\n\n","metadata":{}},{"id":"bffbae28","cell_type":"markdown","source":"","metadata":{}}]}