{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ğŸ”¥ AI-Generated vs. Real Art Classification (CIFAKE Dataset)\n### **Built with CNN & Transfer Learning (ResNet50) + Explainability (Grad-CAM)**\n\n**Author:** Your Name  \n**Objective:** Train a CNN to classify AI-generated vs. real artwork using the CIFAKE dataset.\n\n**ğŸ”¹ Techniques Used:**\n- Convolutional Neural Networks (CNNs)\n- Transfer Learning with ResNet50\n- Data Augmentation & Dropout for Overfitting Prevention\n- Hyperparameter Optimization (Adam, Learning Rate Scheduling)\n- Evaluation Metrics (Confusion Matrix, ROC-AUC, Classification Report)\n- Explainability with Grad-CAM","metadata":{}},{"cell_type":"code","source":"# ğŸ“Œ Step 1: Import Libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“Œ Step 2: Load the CIFAKE Dataset","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images'\nreal_images_path = os.path.join(data_dir, 'real')\nfake_images_path = os.path.join(data_dir, 'fake')\nreal_images = [os.path.join(real_images_path, img) for img in os.listdir(real_images_path)]\nfake_images = [os.path.join(fake_images_path, img) for img in os.listdir(fake_images_path)]\ndf = pd.DataFrame({'image_path': real_images + fake_images, 'label': ['real']*len(real_images) + ['fake']*len(fake_images)})\ndf['label'] = df['label'].map({'real': 1, 'fake': 0})\ndf = df.sample(frac=1).reset_index(drop=True)  # Shuffle dataset\ndf.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“Œ Step 3: Preprocess Images and Create Data Generators","metadata":{}},{"cell_type":"code","source":"img_size = (128, 128)\nbatch_size = 32\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\ntrain_gen = datagen.flow_from_dataframe(df, x_col='image_path', y_col='label', target_size=img_size, batch_size=batch_size, subset='training', class_mode='binary')\nval_gen = datagen.flow_from_dataframe(df, x_col='image_path', y_col='label', target_size=img_size, batch_size=batch_size, subset='validation', class_mode='binary')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“Œ Step 4: Build & Train a CNN Model with Transfer Learning (ResNet50)","metadata":{}},{"cell_type":"code","source":"base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\nbase_model.trainable = False  # Freeze base model layers\nmodel = Sequential([\n    base_model,\n    Flatten(),\n    Dropout(0.3),\n    Dense(128, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_gen, validation_data=val_gen, epochs=5)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“Œ Step 5: Evaluate Performance","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(val_gen) > 0.5\ny_true = val_gen.classes\ncm = confusion_matrix(y_true, y_pred)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\nplt.show()\nprint(classification_report(y_true, y_pred, target_names=['Fake', 'Real']))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ğŸ“Œ Step 6: Explainability using Grad-CAM","metadata":{}},{"cell_type":"code","source":"# Grad-CAM implementation (explainability)\n# [To be implemented for visualization of CNN predictions]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ğŸš€ **Next Steps:**\n- Fine-tune ResNet50 by unfreezing some layers\n- Train with more epochs & experiment with hyperparameters\n- Deploy as a web app using Flask or Streamlit\n\n**ğŸ“Œ If this helped you, consider starring the GitHub repo!** â­","metadata":{}}]}