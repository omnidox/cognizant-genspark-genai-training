{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Text Completion using OpenAI API\n",
    "This notebook demonstrates how to build a simple AI text completion application using OpenAI's API.\n",
    "You will:\n",
    "- Set up your environment and install dependencies.\n",
    "- Obtain and securely store an API key.\n",
    "- Develop a simple text completion function.\n",
    "- Test various prompts and analyze AI behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (1.64.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\users\\omnid\\anaconda3\\envs\\cognizant\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\omnid\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required package\n",
    "%pip install openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Dependencies\n",
    "We will import `openai` for making API calls and `os` to securely load the API key from an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found! Set OPENAI_API_KEY as an environment variable.\")\n",
    "else:\n",
    "    print(\"API key found!\")\n",
    "\n",
    "# Create OpenAI client instance\n",
    "client = openai.OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Text Completion Function\n",
    "This function takes user input and queries OpenAI's API for text completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=100, temperature=0.7):\n",
    "    \"\"\"Generate text completion using OpenAI API (v1.0+).\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Interactive Text Completion\n",
    "Now, you can input a prompt and see how the AI responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Get user input and generate AI response\n",
    "user_prompt = input(\"Enter a prompt for AI completion: \")\n",
    "if user_prompt.strip():\n",
    "    print(\"AI Response:\", generate_completion(user_prompt))\n",
    "else:\n",
    "    print(\"Error: Empty prompt. Please enter a valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Experiment with Different Prompts\n",
    "Try the following prompts to test the AI:\n",
    "- \"Write a poem about the ocean.\"\n",
    "- \"Summarize the theory of relativity in simple terms.\"\n",
    "- \"Complete this sentence: 'Once upon a time, in a land far away...'\"\n",
    "\n",
    "Modify the `temperature` and `max_tokens` values to see how they affect output quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Write a short poem about the ocean.\n",
      "AI Response: The ocean whispers secrets untold,\n",
      "Its vast expanse a sight to behold.\n",
      "Waves crash upon the sandy shore,\n",
      "A symphony of nature's roar.\n",
      "\n",
      "The salty air fills my lungs,\n",
      "As seagulls cry and dolphins run.\n",
      "The water glistens in the sun,\n",
      "A place where all my worries undone.\n",
      "\n",
      "Beneath the surface, a world unknown,\n",
      "Where creatures of all shapes are shown.\n",
      "The ocean's beauty knows no end,\n",
      "A timeless force that will always mend.\n",
      "\n",
      "So\n",
      "\n",
      "Prompt: Summarize the theory of relativity in simple terms.\n",
      "AI Response: The theory of relativity, developed by Albert Einstein, explains how time and space are not fixed but can change depending on an observer's perspective. It also states that the speed of light is constant and the laws of physics are the same for all observers. The theory has two parts: special relativity, which deals with objects moving at constant speeds, and general relativity, which considers acceleration and gravity. Overall, the theory of relativity revolutionized our understanding of the universe and how it works.\n",
      "\n",
      "Prompt: Explain machine learning like I'm five.\n",
      "AI Response: Machine learning is like teaching a computer to solve puzzles by showing it lots of examples and letting it figure out the answers on its own.\n",
      "\n",
      "Prompt: Complete this sentence: 'Once upon a time, in a land far away...'\n",
      "AI Response: there was a magical kingdom where dragons roamed freely and fairies granted wishes to those in need.\n"
     ]
    }
   ],
   "source": [
    "# Testing different prompts\n",
    "test_prompts = [\n",
    "    \"Write a short poem about the ocean.\",\n",
    "    \"Summarize the theory of relativity in simple terms.\",\n",
    "    \"Explain machine learning like I'm five.\",\n",
    "    \"Complete this sentence: 'Once upon a time, in a land far away...'\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"AI Response:\", generate_completion(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Modify AI Behavior\n",
    "Adjusting `max_tokens` and `temperature` can significantly change AI responses:\n",
    "- **Higher `temperature` (0.8 - 1.0)**: More creative but sometimes unpredictable responses.\n",
    "- **Lower `temperature` (0.0 - 0.3)**: More deterministic and straightforward answers.\n",
    "- **Increasing `max_tokens`**: Allows longer responses but may lead to verbosity.\n",
    "\n",
    "Modify the parameters below and observe the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting with different AI parameters:\n",
      "\n",
      "Low Temperature (0.2):\n",
      "The moon is a luminous celestial body that orbits the Earth, reflecting the sun's light to create a mesmerizing glow in the night sky.\n",
      "\n",
      "High Temperature (0.9):\n",
      "The moon shines brightly in the dark night sky, casting a mystical and enchanting glow over the world below.\n",
      "\n",
      "Short Response (max_tokens=50):\n",
      "Once upon a time in a small village nestled in the rolling hills of the countryside, there lived a young girl named Lily. Lily was a curious and adventurous soul, always seeking out new adventures and exploring the world around her. She had long, flowing\n",
      "\n",
      "Long Response (max_tokens=150):\n",
      "Once upon a time in a small village nestled between rolling hills and lush forests, there lived a young girl named Elara. Elara was known throughout the village for her kind heart and adventurous spirit. She spent her days exploring the woods, collecting wildflowers, and playing with the animals that called the forest home.\n",
      "\n",
      "One day, while wandering through the woods, Elara stumbled upon a hidden cave that she had never noticed before. Intrigued, she cautiously entered the dark cavern, her heart pounding with excitement. As she ventured deeper into the cave, she discovered a sparkling crystal hidden in a crevice in the wall. The crystal glowed with a soft, ethereal light, casting a warm glow throughout the cave.\n",
      "\n",
      "Elara was mesmerized\n"
     ]
    }
   ],
   "source": [
    "# Experimenting with different settings\n",
    "print(\"Experimenting with different AI parameters:\")\n",
    "print(\"\\nLow Temperature (0.2):\")\n",
    "print(generate_completion(\"Describe the moon in one sentence.\", temperature=0.2))\n",
    "\n",
    "print(\"\\nHigh Temperature (0.9):\")\n",
    "print(generate_completion(\"Describe the moon in one sentence.\", temperature=0.9))\n",
    "\n",
    "print(\"\\nShort Response (max_tokens=50):\")\n",
    "print(generate_completion(\"Tell me a story as long as you can make it.\", max_tokens=50))\n",
    "\n",
    "print(\"\\nLong Response (max_tokens=150):\")\n",
    "print(generate_completion(\"Tell me a story as long as you can make it\", max_tokens=150))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- Low temperature (0.2) produces direct and factual responses.\n",
    "- High temperature (0.9) makes responses more creative but sometimes unpredictable.\n",
    "- Increasing `max_tokens` generates more detailed outputs but may include unnecessary details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cognizant)",
   "language": "python",
   "name": "cognizant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
