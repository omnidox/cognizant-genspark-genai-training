{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Generating Artistic Abstract Images with GANs\n", "\n", "This notebook explores the use of Generative Adversarial Networks (GANs) to create unique and artistic abstract images.\n", "The project focuses on training a GAN using the [Abstract Art dataset](https://www.kaggle.com/datasets/greg115/abstract-art).\n", "\n", "## Objectives\n", "- Understand how GANs can generate visually diverse artistic outputs.\n", "- Train a GAN using a dataset of abstract art images.\n", "- Generate and evaluate the quality of artistic images produced by the model.\n", "\n", "---\n", "## Part 1: Dataset Preparation"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "load_dataset"}, "outputs": [], "source": ["# Import necessary libraries\n", "import os\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import torchvision.transforms as transforms\n", "import torchvision.datasets as datasets\n", "from torch.utils.data import DataLoader\n", "from torchvision.utils import make_grid\n", "\n", "# Define dataset path\n", "DATA_PATH = '../input/abstract-art/'  # Adjust as needed for Kaggle Notebook\n", "\n", "# Define image transformations\n", "transform = transforms.Compose([\n", "    transforms.Resize((128, 128)),  # Resize images\n", "    transforms.ToTensor(),  # Convert images to tensors\n", "    transforms.Normalize([0.5], [0.5])  # Normalize pixel values to [-1, 1]\n", "])\n", "\n", "# Load dataset\n", "dataset = datasets.ImageFolder(root=DATA_PATH, transform=transform)\n", "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n", "\n", "print(f'Dataset size: {len(dataset)} images')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Part 2: Building the GAN\n", "\n", "### Defining the Generator and Discriminator"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "gan_model"}, "outputs": [], "source": ["# Define the Generator\n", "class Generator(nn.Module):\n", "    def __init__(self, latent_dim=100):\n", "        super(Generator, self).__init__()\n", "        self.model = nn.Sequential(\n", "            nn.Linear(latent_dim, 128*16*16),\n", "            nn.BatchNorm1d(128*16*16),\n", "            nn.ReLU(),\n", "            nn.Unflatten(1, (128, 16, 16)),\n", "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n", "            nn.BatchNorm2d(64),\n", "            nn.ReLU(),\n", "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n", "            nn.Tanh()\n", "        )\n", "\n", "    def forward(self, z):\n", "        return self.model(z)\n", "\n", "# Define the Discriminator\n", "class Discriminator(nn.Module):\n", "    def __init__(self):\n", "        super(Discriminator, self).__init__()\n", "        self.model = nn.Sequential(\n", "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n", "            nn.LeakyReLU(0.2),\n", "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n", "            nn.BatchNorm2d(128),\n", "            nn.LeakyReLU(0.2),\n", "            nn.Flatten(),\n", "            nn.Linear(128*16*16, 1),\n", "            nn.Sigmoid()\n", "        )\n", "\n", "    def forward(self, img):\n", "        return self.model(img)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Training the GAN\n", "\n", "Using an adversarial training loop to optimize both models."]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "train_gan"}, "outputs": [], "source": ["# Hyperparameters\n", "latent_dim = 100\n", "num_epochs = 100\n", "lr = 0.0002\n", "\n", "# Initialize models and optimizers\n", "generator = Generator(latent_dim)\n", "discriminator = Discriminator()\n", "loss_fn = nn.BCELoss()\n", "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n", "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n", "\n", "# Training Loop\n", "for epoch in range(num_epochs):\n", "    for i, (real_imgs, _) in enumerate(dataloader):\n", "        # Train Discriminator\n", "        optimizer_D.zero_grad()\n", "        real_labels = torch.ones(real_imgs.size(0), 1)\n", "        fake_labels = torch.zeros(real_imgs.size(0), 1)\n", "        real_loss = loss_fn(discriminator(real_imgs), real_labels)\n", "        z = torch.randn(real_imgs.size(0), latent_dim)\n", "        fake_imgs = generator(z)\n", "        fake_loss = loss_fn(discriminator(fake_imgs.detach()), fake_labels)\n", "        d_loss = real_loss + fake_loss\n", "        d_loss.backward()\n", "        optimizer_D.step()\n", "\n", "        # Train Generator\n", "        optimizer_G.zero_grad()\n", "        g_loss = loss_fn(discriminator(fake_imgs), real_labels)\n", "        g_loss.backward()\n", "        optimizer_G.step()\n", "\n", "    print(f'Epoch {epoch+1}/{num_epochs} - D Loss: {d_loss.item()} - G Loss: {g_loss.item()}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Generating Abstract Art Images\n", "Visualizing the outputs from the trained generator."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 4}