{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comprehensive Guide: Multi-Label Classification of Research Papers using Azure Machine Learning**\n",
    "This guide provides a **step-by-step tutorial** to **design, implement, and deploy** an **AI solution** for **multi-label classification of research papers** using **Azure AI Studio**.\n",
    "\n",
    "---\n",
    "\n",
    "## **📌 Project Overview**\n",
    "### **🎯 Objective**\n",
    "We will **classify research papers** into **multiple academic domains** using a **pre-trained transformer model** from the **Azure AI Studio Model Catalog**. This AI solution will:\n",
    "✅ Automate research paper classification.  \n",
    "✅ Improve discoverability in academic repositories.  \n",
    "✅ Allow for scalable, cloud-based deployment.\n",
    "\n",
    "---\n",
    "\n",
    "## **📝 Step 1: Define the AI Task**\n",
    "### **✅ Task Definition**\n",
    "- **Goal:** Assign **multiple academic fields** (e.g., *Computer Science, Physics, Mathematics*) to research papers based on their **title and abstract**.\n",
    "- **Dataset:** Kaggle’s **multi-label classification dataset** for **academic papers**.\n",
    "- **Real-World Application:** Used by **academic search engines, journals, and research institutions** to automatically tag papers.\n",
    "\n",
    "---\n",
    "\n",
    "## **🔍 Step 2: Explore the Model Catalog**\n",
    "### **✅ Choose a Pre-trained Model**\n",
    "Azure AI Studio provides **pre-trained models** from:\n",
    "- **Microsoft**\n",
    "- **OpenAI**\n",
    "- **Hugging Face**\n",
    "\n",
    "Since we already fine-tuned **DistilBERT** on a similar dataset, we will:\n",
    "1️⃣ **Use Hugging Face’s DistilBERT model from the Azure Model Catalog.**  \n",
    "2️⃣ **Fine-tune the model on our multi-label dataset.**  \n",
    "3️⃣ **Deploy it as an API using Azure Machine Learning.**\n",
    "\n",
    "---\n",
    "\n",
    "## **📦 Step 3: Manage Your Model in Azure AI Studio**\n",
    "### **✅ Set Up the Environment**\n",
    "1️⃣ **Sign into Azure AI Studio**  \n",
    "- Go to **[Azure AI Studio](https://ai.azure.com/studio/)**.\n",
    "- Create a **new workspace** for the project.\n",
    "\n",
    "2️⃣ **Create an Azure Machine Learning Compute Instance**\n",
    "- In **Azure ML Studio**, navigate to **Compute** → **Create New**.\n",
    "- Choose an **instance with GPU** (e.g., *Standard_NC6* for GPU training).\n",
    "\n",
    "3️⃣ **Organize the Model**\n",
    "- Open **Azure AI Studio**.\n",
    "- Select **Models** → **Browse Model Catalog**.\n",
    "- **Search for \"DistilBERT\"** and select **Hugging Face’s `distilbert-base-uncased`**.\n",
    "\n",
    "4️⃣ **Enable Version Control**\n",
    "- **Register the model** inside your workspace.\n",
    "- Assign a **version number** to track changes.\n",
    "\n",
    "---\n",
    "\n",
    "## **📊 Step 4: Develop the AI Solution**\n",
    "### **✅ 1. Input Data Preparation**\n",
    "#### **1️⃣ Load Dataset from Kaggle**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"/kaggle/input/multilabel-classification-dataset/train.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Merge title and abstract into a single text column\n",
    "df[\"text\"] = df[\"TITLE\"] + \" \" + df[\"ABSTRACT\"]\n",
    "\n",
    "# Define label columns\n",
    "label_columns = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\", \"Quantitative Finance\"]\n",
    "\n",
    "# Ensure labels are binary\n",
    "df[label_columns] = df[label_columns].astype(int)\n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[[\"text\"] + label_columns]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **✅ 2. Convert Data to Azure Dataset**\n",
    "1️⃣ **Upload the dataset to Azure ML**:\n",
    "- Navigate to **Data** → **Upload Data**.\n",
    "- Select **Tabular Dataset**.\n",
    "\n",
    "2️⃣ **Register the dataset**:\n",
    "- Assign a **name** and **version**.\n",
    "\n",
    "---\n",
    "\n",
    "### **✅ 3. Preprocess Text Data**\n",
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load tokenizer from Hugging Face\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Convert Pandas DataFrame to Hugging Face Dataset format\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Tokenize function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **✅ 4. Train DistilBERT on Azure**\n",
    "1️⃣ **Fine-tune model**\n",
    "```python\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load pre-trained DistilBERT for multi-label classification\n",
    "num_labels = len(label_columns)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "```\n",
    "\n",
    "2️⃣ **Set training parameters**\n",
    "```python\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    ")\n",
    "```\n",
    "\n",
    "3️⃣ **Train the model**\n",
    "```python\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **🚀 Step 5: Deploy the Model in Azure**\n",
    "### **✅ Convert Model to ONNX for Azure**\n",
    "1️⃣ **Export model**\n",
    "```python\n",
    "import torch.onnx\n",
    "\n",
    "# Convert to ONNX format\n",
    "dummy_input = torch.ones(1, 512, dtype=torch.int64).to(device)\n",
    "torch.onnx.export(model, dummy_input, \"distilbert.onnx\")\n",
    "```\n",
    "\n",
    "2️⃣ **Upload to Azure**\n",
    "- Go to **Azure ML Studio** → **Models** → **Upload Model**.\n",
    "- Select **distilbert.onnx**.\n",
    "\n",
    "---\n",
    "\n",
    "### **✅ Deploy as an API in Azure**\n",
    "1️⃣ **Create an Azure ML Endpoint**\n",
    "- In **Azure ML Studio**, go to **Endpoints** → **Create New Endpoint**.\n",
    "\n",
    "2️⃣ **Deploy the Model**\n",
    "```python\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core import Workspace, Environment\n",
    "\n",
    "# Load Azure workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Define inference config\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=Environment(\"AzureML-AI\"))\n",
    "\n",
    "# Register the model in Azure\n",
    "model = Model.register(ws, model_name=\"distilbert-paper-classifier\", model_path=\"distilbert.onnx\")\n",
    "\n",
    "# Deploy as an endpoint\n",
    "deployment = Model.deploy(ws, \"paper-classifier-endpoint\", [model], inference_config)\n",
    "deployment.wait_for_completion(show_output=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📊 Step 6: Evaluate the AI Solution**\n",
    "### **✅ Performance Metrics**\n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = trainer.predict(tokenized_dataset)\n",
    "y_pred = (torch.sigmoid(torch.tensor(predictions.predictions)) > 0.5).int().numpy()\n",
    "y_true = np.array([tokenized_dataset[i][\"labels\"] for i in range(len(tokenized_dataset))])\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=label_columns))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **📜 Step 7: Write the Report**\n",
    "Your report should include:\n",
    "\n",
    "📌 **Task Definition**: Why automated paper classification is useful.  \n",
    "📌 **Model Selection**: Justify using **DistilBERT**.  \n",
    "📌 **Management Process**: Version control, dataset handling.  \n",
    "📌 **Solution Development**: Training and deployment process.  \n",
    "📌 **Evaluation Results**: F1-score, precision-recall metrics.  \n",
    "📌 **Future Improvements**: Improve recall with **focal loss**, experiment with **BERT/RoBERTa**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
